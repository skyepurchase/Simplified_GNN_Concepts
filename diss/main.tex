\documentclass[12pt,a4paper,twoside,openright]{report}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[margin=20mm]{geometry}
\usepackage[pdfborder={0 0 0},backref=page]{hyperref}
\usepackage{dissertation}

\include{math_commands}

\begin{document}

\include{metadata}

\bibliographystyle{plain}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Title

\thispagestyle{empty}

\rightline{\LARGE \textbf{\mfullname}}

\vspace*{60mm}
\begin{center}
    \Huge
    \textbf{\mtitle} \\[5mm]
    \mexamination \\[5mm]
    \mcollege \\[5mm]
    \mdate
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Proforma

\pagestyle{plain}

\newpage
\newpage
\section*{Declaration of originality}

I, \mfullname{} of \mcollege, being a candidate for Part II of the Computer Science Tripos, hereby declare that this dissertation and the work described in it are my own work, unaided except as may be specified below, and that the dissertation does not contain material that has already been used to any substantial extent for a comparable purpose. \mconsent

\bigskip
\leftline{Signed \msignature}
\bigskip
\leftline{Date \today}

\chapter*{Proforma}

{\large
\begin{tabular}{p{0.3\linewidth}p{0.6\linewidth}}
    Candidate Number:   & \bf \mcandidate                   \\
    Project Title:      & \bf \mtitle                       \\
    Examination:        & \bf \mexamination, 2023           \\
    Word Count:         & \bf \mwordcount\footnotemark[1]   \\
    Code Line Count:    & \bf \mlinecount\footnotemark[2]   \\
    Project Originator: & \moriginator                      \\
    Supervisor:         & \msupervisor                      \\ 
\end{tabular}
}

\footnotetext[1]{This word count was computed by \texttt{texcount}.}
\footnotetext[2]{This word count was computed by \texttt{cloc}. Only generating bash scripts where considered as the generated files are all structurally identical.}
\stepcounter{footnote}

\section*{Original Aims of the Project}

This project analyses the effect that simplifying graph neural networks (GNNs), through linearisation, has on model performance and why this is the case.
%the graph concepts that are extracted from a trained model.
The project focuses
%specifically on the widely aclaimed
on the Simplified Graph Convolution \cite{wu2019simplifying}[SGC] as a fully linearised model that matches the performance of non-linear GNNs.
%which removes the non-linearity between layers from previous graph neural network approaches reducing the problem of graph representational learning to a precomputation on the graph structure and a single linear regressor.
Using the notion of graph concepts and the metrics proposed in \textit{Magister et. al} \cite{magister2021gcexplainer} the project aims to compare SGC to Graph Convolution Network.
The overall aim of the project is to better understand how linear architectures can achieve graph structure awareness.
These insights then guide extensions into improving linear GNN architectures and reducing computational cost.
%Further extensions then build on SGC to see which techniques can improve accuracy and concept metrics.

\section*{Work Completed}

The project was a success gaining insight into the graph structure awareness of both linear and non-linear models.
The insight gained lead to a novel approach to mixing GNN architectures and a new linear architecture that achieves improved structural awareness comparable to non-linear models.
It further demonstrated that the SGC architecture proposed by \textit{Wu et al.} does not have fine-grained graph structure awareness and demonstrates poor performance on a range of new datasets.
%Furthermore, it demonstrated that in the case of highly synthetic data SGC is unable to match the performance of GCN by a significant margin.
%My extensions demonstrate that in the case of real-world graph datasets, where graph structure is important, SGC continues to underperform compared to GCN and does not produce comparable concepts.
To combat this a novel extension to SGC using jumping knowledge networks\cite{xu2018representation} is presented that demonstrates graph structure awareness in a linear model.
%However, overall SGC does not appear to be a suitable candidate for graph representational learning on its own.
%I additionally set out to create a new parameterised dataset to further analyse the shortcomings of SGC when dealing with graph structure.
%\error{This is still not complete but I am undertaking this task.}

\section*{Special Difficulties}

None

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Chapters

\pagestyle{headings}

\tableofcontents

\input{chapters/introduction}
\input{chapters/preparation}
\input{chapters/implementation}
\input{chapters/evaluation}
\input{chapters/conclusion}

\bibliography{references}

\appendix
\input{appendices/abbreviations}
\input{appendices/hyperparameters}
\input{appendices/concepts}
\input{appendices/proof}
\input{appendices/gcn}
\input{appendices/datasets}
\input{appendices/phase2}

\end{document}
