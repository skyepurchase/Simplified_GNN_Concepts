\section{Related Work}

\paragraph{Graph explainability}
\citet{ying2019gnnexplainer} identifies subgraphs as ideal explainability tools for GNNs as it provides both node and edge information, which are key to graph representational learning, simultaneously. 
%Subgraphs are generated by perturbing the input graph and comparing the model predictions to the original predictions.
%By maximising mutual information it identifies important structures and node features in the input which can be masked to generate subgraphs.
However, their approach focuses on perturbing the input graph resulting in local explanations for each classification rather than desired global explanations.
\citet{luo2020parameterized} combat this by learning optimal perturbations from the edge embeddings thus providing global explanations.
Both techniques learn an additional model to explain the GNN on a specific graph instance.

Instead, \citet{magister2021gcexplainer} provide global, model-level explanations by producing graph concepts.
Concepts are human-interpretable units~\cite{ghorbani2019towards}, in the case of graph concepts these are best represented by subgraphs as demonstrated in Figure \ref{fig:concept}.
These differ from the subgraphs in \citet{ying2019gnnexplainer} and \citet{luo2020parameterized} as they are extracted from the model's activations rather than from input perturbations.
The method achieves this by adapting \citet{ghorbani2019towards} to GNNs and graph data.
%Rather than perturb the input the model's predictions are clustered based on similarity and subgraphs are generated by considering a node's neighbourhood.
%They present two metrics, purity and completeness, to compare different clusterings and identify the optimal subgraphs.
\textit{Magister et al.} apply this method to a \emph{graph convolutional network} (GCN)~\cite{kipf2016semi}, a non-linear GNN, this project extends the work and applies the method to a linear GNN providing a comparison between the two architectures.

\paragraph{Linear graph neural networks}
Attempts to linearise GNNs have mostly focused on linearising GCN~\cite{kipf2016semi} such as \citet{wu2019simplifying} who proposed the original linearised GNN, \emph{simplified graph convolution} (SGC), by removing the non-linearity from the GCN architecture.
%The argument is that the non-linearity in GCN is derived from the current NN research at the time and that this approach was unnecessary.
By removing non-linearity SGC removes the computation of activation functions resulting in a fixed pre-computation and learnable classifier.
SGC is chosen as the linear model to compare to the non-linear GCN.
Furthermore, the proposed SGCN (\note{a reference to sec:SGCN-imp}) extends SGC by reintroducing some non-linearity from GCN.

\citet{chanpuriya2022simplified} propose adaptive SGC (ASGC) which introduces learnable parameters to the pre-computation allowing the model to adapt to heterophilic data.
\citet{chien2020adaptive} identify heterophilic data as a general problem and propose generalised pagerank GNN (GPR-GNN) as a solution.
Both SGC and ASGC are special cases of GPR-GNN where the proposed node representation NN is removed.
%\textit{Chien and Peng} suggest learning hidden node representation using a standard NN and then propagate these features using generalized pagerank.
The proposed JSGC (\note{a reference to sec:Jump-SGC}) is closely related to GPR-GNN removing the node representation NN and replacing GPR with jumping-knowledge networks~\cite{xu2018representation}.
