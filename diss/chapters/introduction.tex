\chapter{Introduction}

% Short introduction giving a full overview

\emph{
    This dissertation explores the effect that simplifying graph neural network (GNN) architectures through linearization has on performance and graph structure awareness.
    It demonstrates that the current approach to linearising GNNs results in poor graph structure awareness but presents two novel approaches to graph representational learning in response.
    The first approach presents a new method of combining GNN architectures and the second demonstrates accurate graph structure awareness whilst remaining linear.
%Specifically it focuses on the ideas of graph concepts which are extracted from the trained model to provide a visual demonstration of which subspaces of the input influence the model's choice of label.
%These concepts are compared to the original Graph Convolution Network (GCN) using the metrics of concept purity and completeness proposed in \textit{Magister et al.} \cite{magister2021gcexplainer}.
%The specific linear model chosen is the Simplified Graph Convolution (SGC) proposed in \textit{Wu et al.} \cite{wu2019simplifying} due to claims that it matches the performance of GCN.
%Further studies are conducted extending the basic architecture of SGC, whilst keeping with the theme of simplified graph neural networks, to see the effect on the accuracy and concept scores.
}

\section{Motivation}
\label{sec:motivation}

% Importance/rise in use of GNNs

% The rise in use of ML systems

%% Wide spread of ML systems in general prevalent in every day use

\emph{Neural networks} (NN) are able to infer complex relationships within data, \emph{graph neural networks} (GNN) extend this functionality to connected systems where predetermined relationships exist between data points.
In these systems, such as social networks\cite{pmlr-v70-gilmer17a} and molecules\cite{DBLP:journals/corr/abs-1806-01973}, the data can be represented as nodes connected by edges in a graph.
However, the popular deep learning approach, of multiple layers separated by non-linear activation functions, has been criticised as unnecessarily complex for these GNN architectures.\cite{wu2019simplifying}
Instead \emph{simplified GNNs} (specifically \emph{linear GNNs}) have been proposed\cite{chanpuriya2022simplified,navarin2020linear,wu2019simplifying} which aim to match the performance of their non-linear counterparts with great success.

\fig{concept}{An example concept from GCN demonstrating that when classifying the top node the model identifies the house structure and attaching arm. Note that the green nodes have different identifiers demonstrating that this is how GCN consistently identifies the top node.}

However, this success has only been demonstrated on a sample of datasets with limited analysis of how linear GNNs work.
This problem extends generally to NNs where understanding how a model works is largely ignored in favour of higher accuracy.
One solution to this problem is the notion of \emph{concepts}, shown in figure \ref{fig:concept}, which are high-level units of information \cite{ghorbani2019towards} with which a NN infers labels.
These units can be visualised in a human-interpretable fashion allowing for a better analysis of NN models.
Extending this notion to GNNs\cite{magister2021gcexplainer,ying2019gnnexplainer} allows for linear GNNs and their non-linear counterparts to be compared providing a better understanding of how they operate.

The insight provided by concepts can highlight the important features of linear GNN models and thus provide further insight into how linearity influences graph structure awareness.
This goal motivates the project which aims to provide a deeper insight into graph representational learning and provide novel techniques to graph structure inference.

%In recent years there has been rapid development and adoption of machine learning systems such as \emph{neural networks} (NN).
%However, methods to explain how these ever larger models work is lagging behind leading to either mistrust in, or worse, blind trust in these systems.
%Though standard NNs are in the mainstream spotlight there is increasing requirement for NNs to infer knowledge about connected systems such as social networks and molecules.
%The mainstream advancements result in increasingly larger \emph{neural network} (NN) models focusing on text and image based input.
%This development makes sense from the perspective of human interaction however these are limited datastructures especially in the ever increasing interaction of digital information.
%Data present in social networks, computational biology, and systems such as smart cities have multiple predefined connections between each data point.
%In these systems the connected structure is important to classification of the individual data-points leading to the concept of \emph{graph data} and the idea of the \emph{graph neural network} (GNN).
%But criticisms of the deep learning (DL) approach to GNNs has resulted in \emph{Linear GNNs} (SGNNs) that remove non-linearity and focus on the additional information provided by the graph connections.
%\note{somewhere else: How do these linear GNNs compare to non-linear GNNs in how they infer labels for graph data?}
%\note{somewhere else: Are there potential insights into how graph structure can be better utilised?}
%\note{somewhere else: This dissertation answers these questions by evaluating an SGNN within an explanability framework and provides new methods of utilising graph data in SGNNs.}

%% Brief description of evolution of GNNs, looking at motivation and use cases

%\paragraph{Graph data}
%Rather than a dataset being only a collection of feature vectors representing observed data points within the problem setting an additional adjacency matrix is also present.
%The adjacency matrix represents the connections between data points that is inherently present in the observed data.
%An example being friendship connections in a social network or bonds between atoms in a molecule.
%This additional structure provides useful information for tasks where the interaction between data points has importance to the data points themselves.
%More complex graph data may also include attributes associated with the connections which can be simple scalars or multidimensional vectors.
%For these reasons graph data is a highly flexible and versatile datastructure promoting complex inference.

%\paragraph{Graph neural networks (GNNs)} 
%are designed to handle graph data where the connections between data points is an important aspect as the data itself.
%The standard form of a GNN 
%\note{make sure this is valid here!}
%consists of multiple layers connected together by a non-linearity step.
%Each layer performs inference on a node's feature vector in the same way as a NN would perform inference.
%The graph structure is utilised by broadcasting this new node representation along the connected edges to neighbouring nodes.
%Each node then aggregates the representations of its neighbouring nodes creating a compact representation of the neighbourhood according to itself.
%The updated representation and aggregation are then combined to produce a final representation before the next layer.
%By using a process known as \emph{message passing} each node's feature vector is updated based on the graph neighbourhood inferring graph structure as well.
%This process, known as \emph{message passing}, allows a GNN to utilise the graph structure and infer more complex relationships between the data points than an ordinary NN.

%% Rapid integration of these systems 

% The lack of clarity in ML systems
% -> Explainability
% -> Concepts

%\paragraph{Linearising NNs}
%Modern specialist computer hardware, such as graphics processing units (GPU), are incredibly efficient at carrying out large linear operations such as matrix multiplication.
%However, the vast majority of NNs contain non-linear operators between generally linear layers.
%The idea of linearising NNs is to remove \emph{some} of the non-linearity in the architecture multiple layers to be combined into a single linear operation.
%Removal the early non-linearity (or all the non-linearity) results in a pre-computation step that can be carried out on an entire dataset before training or inference.
%%Thus in cases where inputs are sampled from a collection of data points this prevents calculating the same operation on the same data point across samples.
%But, it is important that this does not effect the performance of the model.

%\paragraph{Linear GNNs}
%The process of message passing though complex conceptually can easily be decomposed into a linear operation on the graph features and graph adjacency.
%Using the idea of linearising NNs the non-linearity between individual message passing layers can be removed.
%This allows a GNN to pre-compute multiple message passing steps on the graph dataset before inference.
%Inference then results in a simple classification or linear regression task where only a single layer is required.
%This new \emph{linear GNN} (SGNN) remove their non-linear complexities whilst demonstrating comparable performance to standard GNNs.

%\paragraph{Explainability}
%The advancement of new NNs has focused on improving the performance in metrics such as accuracy and training cost which has resulted in impressive models.
%However, these models remain as blackboxes to the users of these systems but equally to the designers.
%Once a model is trained on a specific dataset there is very limited understanding of how the model is analysing the input to produce a result.
%This can and does create a lot of mistrust in NNs as there is a large element of trusting that the output it produces on unseen data will match our expectation.
%The idea of explainability is to provide different methods of visualising how a model works to a human as a form of verification or to provide insight.
%Many different approaches exist including before, during and after training, to varying degrees of explanation.

%% Importance of understanding ML inference
%% -> Link to potential use cases 

%% Issues with interfering with training

%% Recent development in developing frameworks to analyse these aspects
%% The different goals of explainability 

%\paragraph{Concepts}
%A specific form of explainability that is applied after the training of a model \note{Check that this is always the case!} is that of concepts.
%The idea is to find different subspaces of the input space (where each input to tthe NN is some element of the input space) that correspondent to a specific output.
%This way patterns can be found between input and output to verify that the model is behaving as expected.
%In this dissertation the focus is on graph concepts which are subgraphs created from the input graph(s) for the model.
%These subgraphs represent the graph structures that the model is using to carry out inference on specific inputs.
%
%\paragraph{Concepts in simplified GNNs}
%Though SGNNs show competitive performance when looking at classification accuracy they are a black box as with the majority of NNs.
%As SGNNs delay the influence of the models weights until the final classification step this provides an opportunity to see how graph concepts are effected.
%If these models are truly comparable to GNNs then the concepts should demonstrate how the message passing steps operate.
%These results could therefore influence the design of future networks as the DL approach may not be required for graph data. \note{This needs better wording, I don't know how much I agree with it myself.}

%% The idea of a concept
%% The fact in our case this is done after training
%% -> This does not effect training performance

% More efficient systems should not sacrifice ease of understanding

\section{Previous and Related Work}

% GNN Explainer

%% Actually read this paper

% Graph Concepts Explainer

%% The basis of the project, the framework used

%% Introduces the notion of allowing the user to interact with the concepts

%% Provides clear metrics to compare models in regards to concepts

This project is based on the recent work by \textit{Magister et al.} \cite{magister2021gcexplainer} which proposes a new method to graph concepts and introduces two concept metrics.
Using these metrics a linear GNN and its non-linear counterpart are compared to provide more insight into the effect of linearisation.

% Simplifying Graph Convolutional Networks

%% A simplified method based on the structure of graph convolutions

%% A movement away from DNN

\textit{Wu et al.} \cite{wu2019simplifying} introduce the \emph{simplified graph convolution} (SGC) based on the \emph{graph convolution network} (GCN) proposed by \textit{Kipf et al.} \cite{kipf2016semi}.
The method linearises the graph convolution layers in the network allowing these to be pre-computed.
This linear architecture will be used to compare against the non-linear GCN counterpart.

% Simplified Graph Convolution with Heterophily

%% Identifies the heterophily problem with SGC

%% Note this is different from our observed problems

\textit{Chanpuriya et al.} \cite{chanpuriya2022simplified} demonstrate that SGC achieves poor performance on heterophilic data and introduces SGC with heterophily to overcome these issues.
\textit{Navarin et al.} \cite{navarin2020linear} introduce two new linear GNN architectures the introducing exponential and linear parameterised pre-computations.
This project presents two additional approaches to improving the performance of SGC.

% Maybe ablation studies: Pitfalls

\section{Contributions}

% Basic contributions with extending SGC in new ways

This project applies the tools proposed by \textit{Magister et al.} \cite{magister2021gcexplainer} to SGC \cite{wu2019simplifying}.
To achieve a full comparison between the two systems SGC is modified to graph classification tasks.
These results demonstrate a major limitation of SGC on datasets with no node features as it underperforms in terms of concept score and accuracy contrary to current literature.
These results suggest the SGC is primarily focused on tabular data rather than graph data and lacks graph structure awareness.

Two novel extensions to SGC are proposed to improve the accuracy of the model on the synthetic datasets.
The first method proposes a method of combining GNNs using mutual concepts allowing SGC to replace unnecessary non-linearity in GCN.
This approach is shown to be successful though the performance is limited.
The second extension utilises the method of jumping knowledge networks presented in \textit{Xu et al.} \cite{xu2018representation}.
The approach is successful demonstrating graph structure awareness matching GCN whilst remaining negligibly non-linear.

%\note{Hopefully will have implemented the dataset to get a better demonstration of the shortcomings of SGC. I would love to compare multiple techniques: GraphSAGE, GCN, GAT, GIN. Furthermore include an MLP as a baseline, hopefully showing that SGC almost behaves the same as an MLP.}

%% Introduce two new extensions of SGC

%% These extensions are intended to adapt SGC to highly synthetic data 

%% Furthermore the goal is to increase the explainability through increasing concept scores

% An analysis of SGC on synthetic datasets

%% This project (unintentionally) demonstrates the limitation of this simplified model

%% minor point on the importance of fully testing modern models

% -> Hopefully an analysis of SGC itself

% Hopefully a new dataset with capabilities to demonstrate proper Graph learning

% ORIGINAL PROPOSAL INTRODUCTION

%Within the area of geometric deep learning there have been recent ablation studies looking into the effectiveness of Graph Neural Networks (GNNs). The majority of these studies question the effectiveness of the deep neural network approach of multiple layers separated by non-linear function passes when working with geometric datasets (graphs). \cite{wu2019simplifying} introduce a new approach, Simplified Graph Convolution (SGC), which remove these non-linear functions from the network. This reduces the problem to a pre-computation on the graph adjacency matrix and a simple linear regression using a single weight matrix. The pre-computation on the graph adjacency matrix encodes information about message passing between nodes in the graph.  \cite{chanpuriya2022simplified} introduce further variations on SGC that use the same underlying concept of a pre-computation but deal with the parameters differently allowing for more complex associations. In both cases the results show that removing the non-linearity does not hinder the performance of the network and can in fact improve performance.

%Similarly, the has been a lot of interest into explainable artificial intelligence (XAI) to move away from the black box nature of AI models. There exists multiple methods within this field of machine learning and I will specifically focus on the idea of Concepts. Concepts focuses on relating specific outputs of a model to subspaces within its input space, this gives an indication of what the model is using within the input space to infer the given output. The collections of these subspaces are what are known as concepts. This approaches allows a human actor to get a better understanding of the model's inference as they can compare their own intuition of the input to the concepts the model uses to produce the given result.
%\cite{magister2021gcexplainer} introduce GCExplainer which adapts prior techniques to extract high-level concepts from GNNs. The paper focuses on extracting concepts from a Graph Convolutional Network (GCN, \cite{kipf2016semi}) model.
