\chapter{Introduction}

% Short introduction giving a full overview

\emph{
    This dissertation explores the effect that simplifying graph neural network (GNN) architectures through linearization has on performance and graph structure awareness.
    It demonstrates that the current approach to linearising GNNs results in poor graph structure awareness. In response, I present two novel approaches to graph representational learning in response.
    The first approach splices together a linear and non-linear GNNs into a single model and the second demonstrates accurate graph structure awareness whilst remaining quasi-linear.
%Specifically it focuses on the ideas of graph concepts which are extracted from the trained model to provide a visual demonstration of which subspaces of the input influence the model's choice of label.
%These concepts are compared to the original Graph Convolution Network (GCN~\cite{kipf2016semi}) using the metrics of concept purity and completeness proposed in \textit{Magister et al.}~\cite{magister2021gcexplainer}.
%The specific linear model chosen is the Simplified Graph Convolution (SGC) proposed in \textit{Wu et al.}~\cite{wu2019simplifying} due to claims that it matches the performance of GCN~\cite{kipf2016semi}.
%Further studies are conducted extending the basic architecture of SGC, whilst keeping with the theme of simplified graph neural networks, to see the effect on the accuracy and concept scores.
}

\section{Motivation}
\label{sec:motivation}

% Importance/rise in use of GNNs

% The rise in use of ML systems

%% Wide spread of ML systems in general prevalent in every day use

\fig{linear-vs-non-linear}{An overview of how traditional, non-linear GNNs work compared to linear GNNs. The distinction between GNN layers and graph filters is made as linearisation has focused on graph filters ignoring the more complex GNN layer approaches.}

\emph{Neural networks} (NN) are able to infer complex relationships within data, \emph{graph neural networks} (GNN) extend this functionality to connected systems where predetermined relationships exist between data points.
In these systems, such as social networks~\cite{pmlr-v70-gilmer17a} and molecules~\cite{DBLP:journals/corr/abs-1806-01973}, the data can be represented as nodes connected by edges in a graph.
However, the popular deep learning approach, of multiple layers separated by non-linear activation functions, has been criticised as unnecessarily complex for these GNN architectures.~\cite{wu2019simplifying}
Instead \emph{simplified GNNs} have been proposed~\cite{chanpuriya2022simplified,chien2020adaptive,wu2019simplifying} which are either linear or quasi-linear, using one or two non-linear layers.
Figure \ref{fig:linear-vs-non-linear} demonstrates the difference in architecture between traditional, non-linear GNNs and linear GNNs.
These linear models have been shown to match the performance of non-linear GNNs on a limited number of datasets.
However, these datasets represent a small portion of possible graph datasets and little work has been done to understand how these linear GNNs work.

\fig{concept}{An example graph concept from GCN~\cite{kipf2016semi} demonstrating that when classifying the top node the model identifies the house structure and attaching arm. The consistency of the structure suggests that this is important to classifying the top node.}

The lack of understanding extends generally to NNs where explaining how a model works is largely ignored in favour of higher accuracy.
However, both may be achieved as explainability does not fundamentally limit higher accuracy~\cite{zarlenga2022concept}.
Instead, NNs can be described by their input subspaces, referred to as \emph{concepts}, which influence the classification the most.
As an example, Figure \ref{fig:concept} presents a graph concept which can be interpretted as ``a house structure with an attaching arm''.
This demonstrates that the neighbouring nodes and attaching arm are key to classifying the highlighted green node, this information would not be clear when looking at the green node's feature vector.

Concepts can highlight the limitations of linear GNN models, by demonstrating which graph structures and node features cannot be distinguished, and provide further insight into how linearity influences graph structure awareness, by comparing the differences in concepts between linear and non-linear models.
This capability motivates the project which aims to provide a deeper insight into graph representational learning and provide novel techniques to graph structure inference.

%In recent years there has been rapid development and adoption of machine learning systems such as \emph{neural networks} (NN).
%However, methods to explain how these ever larger models work is lagging behind leading to either mistrust in, or worse, blind trust in these systems.
%Though standard NNs are in the mainstream spotlight there is increasing requirement for NNs to infer knowledge about connected systems such as social networks and molecules.
%The mainstream advancements result in increasingly larger \emph{neural network} (NN) models focusing on text and image based input.
%This development makes sense from the perspective of human interaction however these are limited datastructures especially in the ever increasing interaction of digital information.
%Data present in social networks, computational biology, and systems such as smart cities have multiple predefined connections between each data point.
%In these systems the connected structure is important to classification of the individual data-points leading to the concept of \emph{graph data} and the idea of the \emph{graph neural network} (GNN).
%But criticisms of the deep learning (DL) approach to GNNs has resulted in \emph{Linear GNNs} (SGNNs) that remove non-linearity and focus on the additional information provided by the graph connections.
%\note{somewhere else: How do these linear GNNs compare to non-linear GNNs in how they infer labels for graph data?}
%\note{somewhere else: Are there potential insights into how graph structure can be better utilised?}
%\note{somewhere else: This dissertation answers these questions by evaluating an SGNN within an explanability framework and provides new methods of utilising graph data in SGNNs.}

%% Brief description of evolution of GNNs, looking at motivation and use cases

%\paragraph{Graph data}
%Rather than a dataset being only a collection of feature vectors representing observed data points within the problem setting an additional adjacency matrix is also present.
%The adjacency matrix represents the connections between data points that is inherently present in the observed data.
%An example being friendship connections in a social network or bonds between atoms in a molecule.
%This additional structure provides useful information for tasks where the interaction between data points has importance to the data points themselves.
%More complex graph data may also include attributes associated with the connections which can be simple scalars or multidimensional vectors.
%For these reasons graph data is a highly flexible and versatile datastructure promoting complex inference.

%\paragraph{Graph neural networks (GNNs)} 
%are designed to handle graph data where the connections between data points is an important aspect as the data itself.
%The standard form of a GNN 
%\note{make sure this is valid here!}
%consists of multiple layers connected together by a non-linearity step.
%Each layer performs inference on a node's feature vector in the same way as a NN would perform inference.
%The graph structure is utilised by broadcasting this new node representation along the connected edges to neighbouring nodes.
%Each node then aggregates the representations of its neighbouring nodes creating a compact representation of the neighbourhood according to itself.
%The updated representation and aggregation are then combined to produce a final representation before the next layer.
%By using a process known as \emph{message passing} each node's feature vector is updated based on the graph neighbourhood inferring graph structure as well.
%This process, known as \emph{message passing}, allows a GNN to utilise the graph structure and infer more complex relationships between the data points than an ordinary NN.

%% Rapid integration of these systems 

% The lack of clarity in ML systems
% -> Explainability
% -> Concepts

%\paragraph{Linearising NNs}
%Modern specialist computer hardware, such as graphics processing units (GPU), are incredibly efficient at carrying out large linear operations such as matrix multiplication.
%However, the vast majority of NNs contain non-linear operators between generally linear layers.
%The idea of linearising NNs is to remove \emph{some} of the non-linearity in the architecture multiple layers to be combined into a single linear operation.
%Removal the early non-linearity (or all the non-linearity) results in a pre-computation step that can be carried out on an entire dataset before training or inference.
%%Thus in cases where inputs are sampled from a collection of data points this prevents calculating the same operation on the same data point across samples.
%But, it is important that this does not effect the performance of the model.

%\paragraph{Linear GNNs}
%The process of message passing though complex conceptually can easily be decomposed into a linear operation on the graph features and graph adjacency.
%Using the idea of linearising NNs the non-linearity between individual message passing layers can be removed.
%This allows a GNN to pre-compute multiple message passing steps on the graph dataset before inference.
%Inference then results in a simple classification or linear regression task where only a single layer is required.
%This new \emph{linear GNN} (SGNN) remove their non-linear complexities whilst demonstrating comparable performance to standard GNNs.

%\paragraph{Explainability}
%The advancement of new NNs has focused on improving the performance in metrics such as accuracy and training cost which has resulted in impressive models.
%However, these models remain as blackboxes to the users of these systems but equally to the designers.
%Once a model is trained on a specific dataset there is very limited understanding of how the model is analysing the input to produce a result.
%This can and does create a lot of mistrust in NNs as there is a large element of trusting that the output it produces on unseen data will match our expectation.
%The idea of explainability is to provide different methods of visualising how a model works to a human as a form of verification or to provide insight.
%Many different approaches exist including before, during and after training, to varying degrees of explanation.

%% Importance of understanding ML inference
%% -> Link to potential use cases 

%% Issues with interfering with training

%% Recent development in developing frameworks to analyse these aspects
%% The different goals of explainability 

%\paragraph{Concepts}
%A specific form of explainability that is applied after the training of a model \note{Check that this is always the case!} is that of concepts.
%The idea is to find different subspaces of the input space (where each input to tthe NN is some element of the input space) that correspondent to a specific output.
%This way patterns can be found between input and output to verify that the model is behaving as expected.
%In this dissertation the focus is on graph concepts which are subgraphs created from the input graph(s) for the model.
%These subgraphs represent the graph structures that the model is using to carry out inference on specific inputs.
%
%\paragraph{Concepts in simplified GNNs}
%Though SGNNs show competitive performance when looking at classification accuracy they are a black box as with the majority of NNs.
%As SGNNs delay the influence of the models weights until the final classification step this provides an opportunity to see how graph concepts are effected.
%If these models are truly comparable to GNNs then the concepts should demonstrate how the message passing steps operate.
%These results could therefore influence the design of future networks as the DL approach may not be required for graph data. \note{This needs better wording, I don't know how much I agree with it myself.}

%% The idea of a concept
%% The fact in our case this is done after training
%% -> This does not effect training performance

% More efficient systems should not sacrifice ease of understanding

\section{Previous and Related Work}
This project focuses on two different areas of graph representational learning: explainability and linearisation.
Within graph explainability there have been many different methods presented to explain how GNNs work.

\textit{Ying et al.}~\cite{ying2019gnnexplainer} identifies subgraphs as ideal explainability tools for GNNs as it provides both node and edge information, which are key to graph representational leaerning, simultaneously. 
%Subgraphs are generated by perturbing the input graph and comparing the model predictions to the original predictions.
%By maximising mutual information it identifies important structures and node features in the input which can be masked to generate subgraphs.
However, their approach focuses on perturbing the input graph resulting in local explanations for each classification rather than desired global explanations.
\textit{Luo et al.}~\cite{luo2020parameterized} combat this by learning optimal perturbations from the edge embeddings thus providing global explanations.
Both techniques learn an additional model to explain the GNN on a specific graph instance.

Instead, \textit{Magister et al.}~\cite{magister2021gcexplainer} provide global, model-level explanations by producing graph concepts.
Concepts are human-interpretable units~\cite{ghorbani2019towards}, in the case of graph concepts these are best represented by subgraphs as demonstrated in Figure \ref{fig:concept}.
These differ from the subgraphs in \textit{Ying et al.}~\cite{ying2019gnnexplainer} and \textit{Luo et al.}~\cite{luo2020parameterized} as they are extracted from the models activations rather than from input perturbations.
The method achieves this by adapting \textit{automatic concept extraction}~\cite{ghorbani2019towards} to GNNs and graph data.
%Rather than perturb the input the model's predictions are clustered based on similarity and subgraphs are generated by considering a node's neighbourhood.
%They present two metrics, purity and completeness, to compare different clusterings and identify the optimal subgraphs.
\textit{Magister et al.} apply this method to GCN~\cite{kipf2016semi}, a non-linear GNN, this project extends the work and applies the method to a linear GNN providing a comparison between the two architectures.

Attempts to linearise GNNs have mostly focused on linearising GCN~\cite{kipf2016semi} such as \textit{Wu et al.}~\cite{wu2019simplifying} who proposed the original linearised GNN, SGC, by removing the non-linearity from the GCN architecture.
%The argument is that the non-linearity in GCN is derived from the current NN research at the time and that this approach was unnecessary.
By removing non-linearity SGC removes the computation of activation functions resulting in a fixed pre-computation and learnable classifier.
SGC is chosen as the linear model to compare to the non-linear GCN, furthermore the proposed SGCN (\Sref{sec:SGCN}) extends SGC by reintroducing some non-linearity from GCN.

\textit{Chanpuriya et al.}~\cite{chanpuriya2022simplified} propose adaptive SGC (ASGC) which introduces learnable parameters to the pre-computation allowing the model to adapt to heterophilic data.
\textit{Chien et al.}~\cite{chien2020adaptive} identify heterophilic data as a general problem and propose generalised pagerank GNN (GPR-GNN) as a solution.
Both SGC and ASGC are special cases of GPR-GNN where the proposed node representation NN is removed.
%\textit{Chien and Peng} suggest learning hidden node representation using a standard NN and then propagate these features using generalized pagerank.
The proposed JSGC (\Sref{sec:Jump-SGC}) is closely related to GPR-GNN removing the node representation NN and replacing GPR with jumping-knowledge networks~\cite{xu2018representation}.

%This project is based on the recent work by \textit{Magister et al.}~\cite{magister2021gcexplainer} which proposes a new method to extract graph concepts and introduces two concept metrics to compare between extracted concepts.
%Using these metrics a linear GNN and its non-linear counterpart are compared to provide more insight into the effect of linearisation.
%
%The project also implements and extends the work by \textit{Wu et al.}~\cite{wu2019simplifying} who introduce \emph{simplified graph convolution} (SGC)
%The method linearises the graph convolution layers in the network allowing these to be pre-computed.
%This linear architecture will be used to compare against the non-linear GCN~\cite{kipf2016semi} counterpart.
%
%\textit{Chanpuriya et al.}~\cite{chanpuriya2022simplified} demonstrate that SGC achieves poor performance on heterophilic data and introduces SGC with heterophily to overcome these issues.
%\textit{Navarin et al.}~\cite{navarin2020linear} introduce two new linear GNN architectures the introducing exponential and linear parameterised pre-computations.
%This project presents two additional approaches to improving the performance of SGC.

\section{Contributions}

This project applies the graph explainability tools proposed by \textit{Magister et al.}~\cite{magister2021gcexplainer} to the linear model SGC~\cite{wu2019simplifying}.
This provides a new analysis of linear GNN models and their limitations providing new insight into how graph structure is inferred.
These results demonstrate that purely linear models, such as SGC, cannot infer fine-grained graph structure.
The lack of graph structure awareness suggest the SGC is primarily focused on tabular data rather than graph data.

Two novel extensions are proposed to improve the accuracy and graph structure awareness of SGC.
\begin{enumerate}
    \item
        A new model which uses SGC pre-computation with GCN~\cite{kipf2016semi} layers to utilise the efficient pre-computation with the high accuracy GCN layers.
        The architecture removes unnecessary non-linearity from the initial layers of a GCN model by finding an SGC pre-computation that closely resembles the GCN latent space.
        This means that the effect on the final layers of the GCN model is minimised.
    \item
        A new architecture which uses SGC within an adaptation of jumping knowledge networks~\cite{xu2018representation}.
        The architecture aggregates each successive SGC pre-computation so that the model has more control of the node representations.
        This improves the graph structure awareness of SGC whilst remaining quasi-linear.
\end{enumerate}
Both approaches are successful in increasing both graph structure awareness and accuracy demonstrating that graph structure awareness is achievable whilst remaining quasi-linear.

