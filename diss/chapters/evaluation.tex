\chapter{Evaluation}

\section{Success criteria}

\paragraph{Success Criterion}
The original project proposal (\Aref{ch:proposal}) stated the following three criteria for success:
\begin{enumerate}
    \item 
        Implement SGC and extract the concepts used for each of the synthetic datasets.
        \label{crit1}
    \item 
        Implement GCN and extract the concepts to use as a baseline.
        \label{crit2}
    \item 
        Compare the concepts between SGC and GCN using the metrics of concept completeness and concept purity.
        \label{crit3}
\end{enumerate}

\emph{I completely meet all three success criteria.}
In addition to the above project success criteria, and to aid the analysis of SGC compared to GCN, 
I compare the two models to each other in mean \emph{test accuracy}.

\paragraph{Meeting criterion 1}
\note{Link to section in which met.}

\paragraph{Meeting criterion 2}
\Sref{sec:reproduction} verifies that the correct implementation of GCN and concept extraction is used. Results from all datasets are achieved with quantitative and qualitative results.

\paragraph{Meeting criterion 3}
\note{Link to section in which met.}

\section{Methodology}

\subsection{Hyperparameters}

\paragraph{Reproduction}
\textit{Magister et al.}\cite{magister2021gcexplainer} use a GCN model to evaluate their proposed graph concept explainer.
The paper trains and evaluates the model on the same 5 synthetic node classification datasets described in \Sref{sec:synth} and therefore the same hyperparameters are used for the GCN baseline.

\textit{Wu et al.}\cite{wu2019simplifying} states that the weight decay parameter for the Planetoid datasets was found using \texttt{hyperopt} over 60 iterations.
This process was repeated for results reproduction however it was found that the hyperparameters for the learning rate were different from those stated.

The hyperparameters for these models are available in tables \ref{tab:GCN-params} and \ref{tab:SGC-reproduction-params}.
Additionally the concept extraction metrics are presented in \ref{tab:GCN-concept-params}.

\input{tables/GCN-params}
\input{tables/SGC-reproduction-params}
\input{tables/GCN-concept-params}

\paragraph{New models}
This project proposes multiple new models designed for the different datasets.
The core project defines 5 models based on the SGC architecture as required by criterion \ref{crit1}.
As the underlying graph operator is the same for both GCN and SGC, as described in \Sref{sec:GCN} and \Sref{sec:SGC} the degree of the SGC model can be assumed to be the same as the GCN model for the same dataset.
This the same approach that \textit{Wu et al.}\cite{wu2019simplifying} take to creating there SGC models.

The learning rate for SGC models is likely to be different from the GCN models due to the reformulation.
Furthermore, \textit{Wu et al.}\cite{wu2019simplifying} use weight decay to keep weight values close to $0$ as would be assumed from the multiplication of weight matrices in equation \ref{eq:theta}.
Rather than use stochastic approaches to finding these hyperparameters a sweep of anticipated values is carried out.
This allows for a visualisation of the hyperparameter allowing for further exploration if necessary.
The learning rate is sampled from $\{0.01, 0.001, 0.0001\}$ and the weight decay from $\{1.0, 0.1, 0.01\}$.

The results of these searches is presented in figures \note{include the references the hyperparameter surfaces}.
As can be seen for the majority of hyperparameter searches the specific hyperparameters have minimal to no impact on the resulting model accuracy and therefore $0.01$ is chosen for learning rate and $0.1$ for weight decay.
The hyperparameters chosen are presented in table \ref{tab:SGC-params}

\input{tables/SGC-params}

\paragraph{Datasets}
The batch sizes for all the datasets match those described in \textit{Ying et al.}\cite{ying2019gnnexplainer} and \textit{Kipf et al.}\cite{kipf2016semi}.
The number of epochs for each dataset matches those proposed in \textit{Magister et al.}\cite{magister2021gcexplainer} and \textit{Wu et al.}\cite{wu2019simplifying} or until convergence for SGC.

\subsection{Model Evaluation}

Criterion \ref{crit3} requires evaluation of the models with respect to concept purity and completeness.
These metrics are discussed in \ref{sec:GCE} and implementation is described in \note{reference when complete}.
On top of the quantitative analysis of the different models concepts lend themselves to qualitative analysis which will mainly focus on visual similarities between the two models.
the quantitative analysis will also help to infer the differences in how the two models infer labels on the input data.

It is important to note a number of drawbacks of the GCExplainer in comparing two different models.
\begin{enumerate}
    \item 
        Concept purity is calculated only using subgraphs with less than 13 nodes.
        This means that pure quantitative analysis does not represent a full comparison of the two models.
    \item 
        The number of clusters and the receptive field of the concepts can be arbitrarily manipulated to find the highest score.
        To combat this the new SGC models are compared against the same concept extraction parameters presented in table \note{reference when completed}.
    \item 
        \textit{Ying et al.}\cite{ying2019gnnexplainer} only suggest concept extraction for models that achieve an accuracy of atleast $95\%$ on synthetic datasets. 
\end{enumerate}

The final point motivates the additional evaluation metric of accuracy as \Sref{sec:comparison} demonstrates that SGC does not meet the desired accuracy.
To evaluate this the 

\paragraph{Confidence intervals}

\subsection{Concept Evaluation}

\subsection{Reproducibility}

\subsection{Specifications}
The experiments are not resource-intensive due to the incredibly small datasets and so carrying out the hyperparameter search and multiple final runs can be completed on my personal machine.
My machine has an AMD Ryzen 7 5700U CPUs @ 1.8GHz with 16 cores wuth 15 Gigabytes of RAM.
The machine does have an AMD ATI Lucienne GPU but due to the fact that \texttt{PyTorch Geometric}\note{citation needed} did not support RoCM I was unable to utilise this.

To speed up the retrieval of experimental results for extensions I utilised a Google Colab Pro account with 1 hyperthreaded Intel Xeon Processor @ 2.3GHz with 1 core and 12 Gigabytes of Ram.
The account also has access to a Tesla K80 GPU with 12GB of RAM.

\note{Include figures demonstrating system use later.}

\section{Results Reproduction}
\label{sec:reproduction}

\input{tables/SGC-reproduction}
\input{tables/GCN-acc}
\input{tables/GCN-concepts}

\section{Comparison of Accuracy}
\label{sec:comparison}

\input{tables/SGC-acc}

\section{Comparison of Concept Scores}

\input{tables/SGC-concepts}

\section{Extensions}

\subsection{SGC Graph Classification}

\subsection{SGC and GCN Mixed Model}

\subsection{JumpNet style SGC}

