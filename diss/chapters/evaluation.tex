\chapter{Evaluation}
\label{ch:evaluation}

\section{Success criteria}

\paragraph{Success Criterion}
The original project proposal (\Aref{ch:proposal}) stated the following three criteria for success:
\begin{enumerate}
    \item 
        Implement SGC and extract the concepts used for each of the synthetic datasets.
        \label{crit1}
    \item 
        Implement GCN and extract the concepts to use as a baseline.
        \label{crit2}
    \item 
        Compare the concepts between SGC and GCN using the metrics of concept completeness and concept purity.
        \label{crit3}
\end{enumerate}

\emph{I meet all three success criteria.}
In addition to the above project success criteria, and to aid the analysis of SGC compared to GCN, the two models are compared using mean \emph{test accuracy}.

\paragraph{Meeting criterion 1}
\Sref{sec:datasets-imp} details the implementation of the SGC pre-computation and \Sref{sec:reproduction} verifies the correctness of the implementation.
\Sref{sec:comp-concept} demonstrates concept extraction on the synthetic datasets.

\paragraph{Meeting criterion 2}
\Sref{sec:models} details the implementation of the GCN model.
\Sref{sec:reproduction} verifies the correctness of the GCN implementation and demonstrates concept extraction.

\paragraph{Meeting criterion 3}
\Sref{sec:concepts} details the implementation of concept extraction, calculation and visualisation.
\Sref{sec:comp-concept} demonstrates the comparison of SGC and GCN using the metrics of concept completeness and purity.
Additionally, \Sref{sec:comp-acc} presents a comparison between the accuracy of the models.

\section{Methodology}

\subsection{Hyperparameters}
\label{sec:hyperparameters}

\paragraph{Reproduction}
\textit{Magister et al.}~\cite{magister2021gcexplainer} use a GCN model to evaluate their proposed GCExplainer on the 5 synthetic node classification datasets described in \Sref{sec:synth}.
The hyperparameters used are presented in Table 15 from \textit{Magister et al.}. 

\textit{Wu et al.}~\cite{wu2019simplifying} use hyperopt to find the weight decay parameter for the Planetoid~\cite{kipf2016semi} datasets.
This process was repeated however it was found that the learning rates were different from those stated.

The hyperparameters for these models are available in Tables \ref{tab:GCN-params} and \ref{tab:SGC-reproduction-params}.
Additionally, the concept extraction metrics are presented in Table \ref{tab:GCN-concept-params}.

%\input{tables/GCN-params}
%\input{tables/SGC-reproduction-params}
%\input{tables/GCN-concept-params}

\paragraph{New models}
The core project defines 5 models based on the SGC architecture as required by criterion \ref{crit1}.
As the underlying graph operator is the same for both GCN and SGC the degree of the SGC model is the same as the number of layers in GCN.
This is the approach that \textit{Wu et al.}~\cite{wu2019simplifying} use to create their SGC models.

The learning rate for SGC models is likely to be different from the GCN models due to the reformulation.
Furthermore, \textit{Wu et al.}~\cite{wu2019simplifying} suggest using weight decay to keep weight values close to $0$.
%as would be assumed from the multiplication of weight matrices in equation \ref{eq:theta}.
Rather than stochastic approaches to finding hyperparameters a sweep of values is tested.

The result of these searches is presented in Figures \ref{fig:SGC-surfaces} and \ref{fig:JSGC-surfaces}.
The majority of sweeps demonstrate minimal impact on model accuracy and therefore a learning rate of $0.01$ and weight decay constant of $0.1$ is chosen.
The hyperparameters used are presented in Table \ref{tab:SGC-params}.

%\input{tables/SGC-params}

\paragraph{Datasets}
The batch sizes for all the datasets match those described in \textit{Ying et al.}~\cite{ying2019gnnexplainer} and \textit{Kipf et al.}~\cite{kipf2016semi}.
The number of epochs for each dataset matches those proposed in \textit{Magister et al.}~\cite{magister2021gcexplainer} and \textit{Wu et al.}~\cite{wu2019simplifying} or until convergence for SGC.

\subsection{Model Evaluation}
\label{sec:evaluation}

\paragraph{Concept evaluation}
Criterion \ref{crit3} requires quantitative evaluation of the models using concept purity and completeness.
Concepts also lend themselves to qualitative analysis which focuses on visual similarities and will help in understanding the differences in how the two architectures work.

For qualitative analysis only BA Shapes and Mutagenicity will be covered in detail.
A brief analysis of the other datasets is presented in \Aref{app:concepts}.
Extensions only use a subset of datasets.

It is important to note several drawbacks of the GCExplainer in comparing two different models quantitatively.
\begin{enumerate}[nolistsep]
    \item 
        Concept purity is calculated only using subgraphs with less than 13 nodes.
    \item 
        \label{nb:accuracy}
        \textit{Ying et al.}~\cite{ying2019gnnexplainer} only suggest concept extraction for models that achieve an accuracy of at least $95\%$ on synthetic datasets. 
\end{enumerate}

%The full comparison of concepts requires a qualitative analysis of the extracted concepts.
%The concepts produced by SGC can be analysed in isolation to infer how SGC reasons about graphs.
%These can then be compared to the concepts produced by GCN to highlight the differences in reasoning and which is easier to understand.
%When reproducing results this is done by comparing the analysis suggested by \textit{Magister et al.}~\cite{magister2021gcexplainer} to the reproduced concepts.
%Furthermore, a visual comparison of the concepts can be made, such as matching published concepts to reproduced concepts.

\paragraph{Accuracy evaluation}
Drawback \ref{nb:accuracy} motivates the additional evaluation metric of accuracy as \Sref{sec:comp-acc} demonstrates that SGC does not meet the desired accuracy.
To achieve this each synthetic dataset is split into a train and test set using an 80:20 split.
Note that TUDataset~\cite{Morris+2020} and Planetoid~\cite{kipf2016semi} use their own train/test splits.

The synthetic datasets are generated randomly along with the train/test split and thus each random seed produces a new variation.
This means that using the same seed results in the same train/test split.
To keep the final evaluation test nodes unseen during hyperparameter sweeps different seed values are used.
Thus, the hyperparameter search can evaluate parameters on the test split and keep the evaluation test nodes unseen.

\subsection{Confidence intervals}
\label{sec:reporting}
The mean accuracy across 10 different initialisations is reported using $\mu = \sum_i\frac{\text{accuracy}_i}{10}$ as an unbiased estimator of the mean.
The confidence interval of each of the runs uses the unbiased standard deviation estimator $\sigma = \sqrt{\sum_i(\text{accuracy}_i - \mu)/(10 - 1)}$.
For experiments where very high variance is present outliers are removed based on the median, $m$, and the interquartile range, $\text{ITR}$, of the accuracies.\footnote{In the cases where outliers are removed the estimators are adjusted accordingly.}
An outlier is defined as being outside the range $[m - 1.5 \times \text{ITR}, m + 1.5 \times \text{ITR}]$.


\subsection{Reproducibility}
The project fulfils the requirements and suggestions for machine learning projects and experimental results in \href{https://www.cs.mcgill.ca/~jpineau/ReproducibilityChecklist-v2.0.pdf}{\textit{The Machine Learning Reproducibility Checklist}}~\cite{pineau2021improving} 

\subsection{System specifications}
The experiments are not resource-intensive due to the small datasets and so carrying out the hyperparameter search and multiple final runs can be completed on a single machine.
I used an AMD Ryzen 7 5700U CPUs @ 1.8GHz with 16 cores with 15 Gigabytes of RAM.
The machine does have an AMD ATI Lucienne GPU but since \texttt{PyTorch Geometric}~\cite{paszke2019pytorch} did not support RoCM I was unable to utilise this.

To speed up the hyperparameter sweep I utilised a Google Colab Pro account with 1 hyperthreaded Intel Xeon Processor @ 2.3GHz and 12 Gigabytes of RAM.
The account also has access to a Tesla K80 GPU with 12GB of RAM.

\section{Results Reproduction}
\label{sec:reproduction}

As discussed in \Sref{sec:testing} the testing strategy includes the reproduction of prior results from \textit{Magister et al.}~\cite{magister2021gcexplainer} on GCN and \textit{Wu et al.}~\cite{wu2019simplifying} on SGC.
I reproduce all of the experiments from \textit{Magister et al.} and the Planetoid~\cite{kipf2016semi} from \textit{Wu et al.} as these are most relevant.

\paragraph{Success criterion}
\Sref{sec:GCN-reproduction} demonstrates an implementation of GCN trained on the synthetic datasets with concept extraction.
Tables \ref{tab:GCN-acc} and \ref{tab:GCN-concepts} and Figure \ref{fig:GCN-BA-Shapes} demonstrate the results achieved.
This fulfills the \ref{crit2}$^{nd}$ success criterion.

\paragraph{Method}
In both cases across all datasets the hyperparameters presented in Tables \ref{tab:GCN-params} and \ref{tab:SGC-reproduction-params} are used.
Each experiment is run 10 times with different randomly pre-selected seeds and the mean and confidence intervals are presented.
The implementation of the SGC pre-computation is presented in \Sref{sec:datasets-imp}.
The implementation of GCN uses the layers provided by \texttt{PyTorch Geometric}~\cite{Fey/Lenssen/2019}.

\subsection{SGC}
\input{tables/SGC-reproduction}

Table \ref{tab:SGC-reproduction} presents the accuracy achieved by the reproduced SGC models compared to the accuracy presented in Table 2 of \textit{Wu et al.}~\cite{wu2019simplifying}.
As can be seen in both Cora and Citeseer the accuracies are closely correlated.
In comparison, Pubmed presents a large discrepancy between the published result, 78.9\%, and the reproduced result, 71.3\%, with large variation in the reproduced result, $\pm 2.1$.
These discrepancies are due to the uncertainty in hyperparameters as the exact weight decay constant used is unknown.
Furthermore, the published learning rate of 0.2 yields worse results and so new learning rates are used (Table \ref{tab:SGC-reproduction-params}).
Based on these considerations I consider my implementation of SGC to be correct.

\subsection{GCN}
\label{sec:GCN-reproduction}
\paragraph{Accuracy}
\input{tables/GCN-acc}
Table \ref{tab:GCN-acc} presents the accuracy achieved by the reproduced GCN models compared to the accuracy published in Table 16 of \textit{Magister et al.}~\cite{magister2021gcexplainer}.
Overall, the reproduced accuracy matches or exceeds the accuracy presented by \textit{Magister et al.}.
Given the small size of the synthetic datasets, it is expected that nearly 100\% accuracy is achieved.
For the real-world datasets, the expectation is above 85\% as suggested by \textit{Ying et al.}~\cite{ying2019gnnexplainer}.

BA Community is a significant outlier in the results achieving 86.3\% which is neither close the published result, 95.7\%,  nor the suggested 95\%.
However, if the model is allowed to train for more than 6000 epochs an accuracy exceeding 95\% is achieved.
Due to these considerations, the implementation of GCN is deemed to be correct.

\paragraph{Concept scores}
\input{tables/GCN-concepts}
Table \ref{tab:GCN-concepts} presents the concept scores for each of the top performing GCN models compared to those in tables 4 and 5 in \textit{Magister et al.}.
As with the accuracy the concept completeness scores are closely correlated for the majority of the models.
The discrepancy between completeness scores are small, the largest being $-$0.055, which can be attributed to slight variation in the training of the decision tree.

Mutagenicity is an outlier, achieving 0.626 compared to the published 0.967.
This is because extracting concepts requires a single forest of graphs be used instead of individual graphs and this change causes the accuracy to fall to 67.1\%.
This does not effect REDDIT BINARY, 0.713 compared to 0.746, and so I consider this a problem with this specific model.
%\fig{erroneous-labels}{A subset of the concepts discovered for Mutagenicity highlighting the erroneous labels. Each row represents a concept and the graphs are coloured according to standard chemical colouring.}
%
%Figure \ref{fig:erroneous-labels} demonstrates that the clustering for Mutagenicity focuses on chemical similarity which does not necessarily correlate to mutagen similarity.
%This means that the concept completeness is likely to be low as demonstrated in \ref{tab:GCN-concepts} though the actual model accuracy may be high.

In contrast to completeness, Table \ref{tab:GCN-concepts} shows average purity has little correlation between the two results.
This is due to the 13-node cut-off and non-deterministic nature of $k$-Means clustering.
%rather than an incorrect implementation.


\begin{figure}
    \centering
	\captionsetup{width=.9\textwidth}
    \includegraphics[width=0.49\textwidth]{figures/GCN-BA-Shapes}
    \includegraphics[width=0.49\textwidth]{figures/Magister-BA-Shapes}
    \caption{A subset of concepts discovered for BA-Shapes from the best performing GCN model compared to those published in figures 2, 3, and 5 in \textit{Magister et al.}~\cite{magister2021gcexplainer}. Green nodes highlight the node of interest and pink nodes highlight the neighbourhood used for inference. Each row represents an individual concept.}
    \label{fig:GCN-BA-Shapes}
\end{figure}

%\fig{GCN-BA-Shapes}{A subset of concepts discovered for BA-Shapes from the best perfomring GCN model. Green nodes highlight the node of interest and pink nodes highlight the neighbourhood used for inference. Each row represents an individual concept.}
%
%\fig{Magister-BA-Shapes}{A subset of the BA Shapes concepts discovered in figures 2, 3 and 5 from \textit{Magister et al.}~\cite{magister2021gcexplainer} to demonstrate the full range of labels. Each row represents an individual concept, the same colour system is used as fig. \ref{fig:GCN-BA-Shapes}.}

Figure \ref{fig:GCN-BA-Shapes} presents a comparison of BA Shapes concepts reproduced by the best performing GCN model and those published in \textit{Magister et al.}
%Concept 1 and A are included to demonstrate that the model does identify the base graph.
%The remaining concepts demonstrate the 3 other labels associated with the house motif, as discussed in \Sref{sec:synth}.
All the published concepts have an equivalent concept in the reproduced concepts.
%In both models the edge attaching the house motif to the base graph is important to the classification of the nodes.
%The same distinction between concepts 2 and 3 as concepts B and C representing ``inside'' and the ``outside'' nodes respectively is also present in both.
%Notice that in both concept 2 and B the  ``inside'' node clearly attaches to the Barabasi-Albert base graph.
%This distinction is also present in concept 4 and D, with both the published and reproduced concepts focusing on the ``inside'' bottom node.
In both models, the concepts are almost pure except for Concepts 2 and B.
Additionally, all the nodes in the house motif have a unique concept where applicable and this leads to the high completeness score.

Given the visual similarity in concepts between the published and reproduced results I consider the implementation of GCN to be accurate.
Examples of concept extracted from the other datasets are available in \Aref{app:concepts}.

\section{Comparison of Accuracy}
\label{sec:comp-acc}
\input{tables/SGC-acc}

Table \ref{tab:SGC-acc} demonstrates the mean accuracies achieved by each of the SGC models using the hyperparameters in \ref{tab:SGC-params}.
The accuracies achieved by GCN are included and as the performance of SGC is very low random guesses are included.

\paragraph{Compared to GCN}
the accuracies achieved by SGC are significantly worse and go against \textit{Wu et al.}'s claim that SGC can match GCN performance.
Overall, the accuracy achieved by SGC is roughly $50\%$ less than that achieved by GCN.
BA Grid, the highest performing dataset, achieves $72.4\%$, $27.1\%$ less than GCN.
%does SGC achieve a good accuracy in comparison to GCN though even here the difference in accuracy is $27.1$\%.

These poor results suggest that the graph structure awareness of SGC is far worse than that of GCN as the synthetic dataset labels are based only on graph structure.
This is also an explanation for why SGC can surpass the accuracy of GCN in the Planetoid~\cite{kipf2016semi} datasets as these datasets rely heavily on node representations.

\paragraph{Compared to random guesses}
SGC does not perform significantly better than random guesses except in the cases of BA Shapes, 61.4\% compared to 25\% for random, and BA Grid, 72.4\% compared to 50\% for random.
In the cases of the Tree datasets, this can be attributed to the sparsity of the base graph where the motif structure and BST structure share similar connectivity.
In comparison, the dense BA graph allows for a better distinction between the motifs and the base graph.

This ability to distinguish structures based on density is attributed to the degree normalisation present in Equation \ref{eq:op}.
This advantage is not present in BA Community due to the communities and the possibility of a motif having multiple connections to different base graphs.

These results are not due to poor hyperparameter selection as demonstrated in \Aref{app:hyperparameters} and discussed in \Sref{sec:hyperparameters}.
Instead, the explanation for the poor performance is due to the lack of graph structure awareness.

\paragraph{Comparison of parameters}
Given that SGC uses a single classifier layer compared to GCNs multiple layers there is a large discrepancy in the number of parameters\footnote{SGC has roughly 40 parameters compared to GCN with $>$1000 for BA Shapes. Though the GCN model was not optimised for parameter size.}.
However, increasing the parameters for SGC by either increasing the node feature size or adding a \emph{multi-layer perceptron}(MLP) with the same hidden layers as the GCN model results in no substantial change to accuracy.\footnote{The use of an MLP classifier also introduces non-linearity though the model does not improve. Non-linearity and parameters on their own are not sufficient.}

No MLP model is added before the SGC pre-computation step as this goes against linearisation.
This identifies another drawback of SGC: it cannot manipulate the node representations except through neighbourhood aggregation during the pre-computation.
These claims are further explored in \Sref{sec:comp-concept}.

\section{Comparison of concepts}
\label{sec:comp-concept}

To achieve the \ref{crit1}$^{st}$ and \ref{crit3}$^{rd}$ success criterion concepts need to be extracted from SGC and compared to GCN concepts.
However, concept extraction and analysis are only suggested for models that achieved 95\% or higher on synthetic datasets by \textit{Ying et al.}~\cite{ying2019gnnexplainer}.
Table \ref{tab:SGC-acc} demonstrates that SGC does not reach this threshold as the maximum accuracy achieved is 72.4\% on BA Grid.

However, the concepts will still provide insight into the claims in \Sref{sec:comp-acc}.
Furthermore, the concepts highlight the shortcomings of SGC when it comes to graph structure awareness.
Therefore, though the analysis of the concept scores is limited the qualitative concept analysis provides insight into where SGC fails.

\paragraph{Success criterion}
Table \ref{tab:SGC-acc} demonstrates an implementation of SGC trained on the synthetic datasets with Tables \ref{tab:SGC-completeness} and \ref{tab:SGC-purity} showing concept extraction.
Figures \ref{fig:SGC-BA-Shapes} and \ref{fig:BA-Community} visualise the extracted concepts from the relevant SGC model. These fulfill the \ref{crit1}$^{st}$ success criterion.

Table \ref{tab:SGC-completeness} and \ref{tab:SGC-purity} also include a comparison to the scores achieved by GCN.
\Sref{sec:comp-concept} includes a detailed analysis of the concepts extracted for SGC and a comparison to those extracted for GCN.
These fullfil the \ref{crit3}$^{rd}$ success criterion.

\subsection{Quantitative analysis}
\label{sec:quant}
\paragraph{Completeness}
\input{tables/SGC-completeness}

Table \ref{tab:SGC-completeness} demonstrates the completeness scores achieved by SGC compared to GCN and as expected they are consistently lower than the equivalent GCN models.
GCN surpasses SGC by at least 0.075, in Tree Grid, and up to 0.430, in Mutagenicity, well outside of discrepancies in decision tree training.
Though the majority of completeness scores are high exceeding $\approx 0.850$.

These high completeness scores are because completeness relates to the importance of concepts and not directly to the performance of the model.
The relatively high completeness scores for SGC signify that the concepts have some relevance to the node class.
However, as demonstrated by Table \ref{tab:SGC-completeness}, this relevance is not as strong as that in GCN.

\paragraph{Purity}
\input{tables/SGC-purity}

Table \ref{tab:SGC-purity} includes the purity scores achieved by the best-performing SGC models compared to the corresponding GCN models.
As discussed in \Sref{sec:GCN-reproduction} the values for purity are likely to be very erratic.
Considering this, the values for purity are somewhat correlated with SGC achieving fairly pure concepts with all values less than 4.5.
BA Grid is able to achieve completely pure concepts, 0.0, but this is because only two concepts have less than 13 nodes.

The inclusion of the number of concepts considered when calculating purity demonstrates the limitation of purity as it may only represent a small sample.
This is due to the concepts associated with the base graphs are exclued as they contain more than 13 nodes.

Overall, this demonstrates that though SGC does not perform as well as GCN it does produce coherent concepts.

\subsection{Qualitative analysis}
\label{sec:concept-analysis}

\paragraph{BA Shapes}

\begin{figure}
    \centering
	\captionsetup{width=.9\textwidth}
    \includegraphics[width=0.9\textwidth]{figures/SGC-BA-Shapes}
    \caption{A subset of concepts extracted from the best performing SGC model. The subset includes both pure and impure concepts. The same colour scheme as fig. \ref{fig:GCN-BA-Shapes} is used.}
    \label{fig:SGC-BA-Shapes}
\end{figure}

%\fig{SGC-BA-Shapes}{A subset of concepts extracted from the best performing SGC model. The subset includes both pure and impure concepts. The same colour scheme as fig. \ref{fig:GCN-BA-Shapes} is used.}

Figure \ref{fig:SGC-BA-Shapes} visualises a subset of the concepts extracted for SGC on BA Shapes.
Concepts 1 to 4 demonstrate the purer concepts extracted for SGC with Concepts 5 to 7 representing the common impure concepts.
Concept 5 demonstrates a shortcoming of calculating purity: this is considered a ``pure'' concept but is clearly impure as the house structure and BA structure are not isomorphic (the Barabasi-Albert graphs are not considered in calculation). 

Concepts 2, 3 and 4 demonstrate that SGC can identify pure concepts with important graph structure components as they clearly demonstrate the identification of the house structure and attaching arm.
These concepts can be directly compared to Concepts 3, 2 and 4 in Figure \ref{fig:GCN-BA-Shapes} respectively.
As with GCN, the attaching arm is important to the classification of the nodes and there is some distinction between ``inside'' and ``outside'' nodes.
However, as can be seen in Concept 2, this distinction is not as strong as GCN as both ``inside'' and ``outside'' nodes are included together.

Concepts 5, 6 and 7 demonstrate the impure concepts that are extracted from SGC.
This demonstrates that SGC cannot consistently distinguish between the base graph and the motif.
%Given that the nodes of interest in house motif are all consistent across these concepts suggests that there is an element of structure being identified.
These observations are hypothesised to be a result of limited influence on intermediate representation.
Though Equation \ref{eq:theta} suggests that the GCN node manipulation should be preserved the reality is that only the final filter output is manipulated.
This observation leads to the extension presented in \Sref{sec:Jump-SGC} allowing SGC to access intermediate representations.

\paragraph{BA Community}
\begin{figure}
    \centering
	\captionsetup{width=.9\textwidth}
    \includegraphics[width=0.9\textwidth]{figures/SGC-BA-Community}
    \includegraphics[width=0.9\textwidth]{figures/GCN-BA-Community}
    \caption{Comparison of SGC and GCN concepts for BA Community demonstrating the poor graph structural inference of SGC. The numbered concepts are a subset of SGC concepts and the lettered concepts are GCN concepts. The colour scheme is the same as fig. \ref{fig:GCN-BA-Shapes}.}
    \label{fig:BA-Community}
\end{figure}

Figure \ref{fig:BA-Community} highlights the inability of SGC to accurately discern graph structure where GCN demonstrate accurate graph structure awareness.
Concepts 1, 2 and 3 demonstrate the purer concepts for SGC trained on BA Community and Concepts A to E represent the equivalent concepts for GCN.

SGC may be able to identify basic graph structure, as shown by the house structures in Concepts 1 and 2, however, it cannot distinguish between nodes within the same graph structure, as demonstrated by Concept 1.
Comparatively Concepts A, B and C show similar structures with consistent labels across the concepts.

Furthermore, Concept 2 groups nodes from the second community, labels 4, 5, 6, and 7, together ignoring graph structure.
In comparison, GCN can distinguish between members in the same community demonstrated by Concepts B(label 6) and C (label 5).
Additionally, GCN can identify different communities as Concepts A and B represent the same node in the house motif but represent different communities.
%This erroneous behaviour is not standard as concept 3 highlights how the Barabasi-Albert subgraphs from separate communities are grouped together.
GCN always treats the two communities differently regardless of structural similarity which is clear demonstrated in Concepts D and E.

Overall SGC can infer basic graph structure or communities but is unable to achieve both.
Though apparent in BA Community these affect the performance of SGC on other datasets.

\subsection{Summary}
%The low accuracy of SGC means that the data present in tables \ref{tab:SGC-completeness} and \ref{tab:SGC-purity} does not carry much meaning.
%However, table \ref{tab:SGC-completeness} does suggest that SGC does not produce useful Concepts even though table \ref{tab:SGC-purity} suggests that these concepts are coherent.

SGC is not as capable as GCN when dealing with synthetic datasets where graph structure is important.
Table \ref{tab:SGC-acc} demonstrates poor performance across all of the synthetic datasets and Tables \ref{tab:SGC-completeness} and \ref{tab:SGC-purity} show the corresponding low concept scores.
Attempts to improve the performance by increasing the parameters of SGC have resulted in no substantial improvement in accuracy or concept score.

The concepts extracted from SGC across the datasets demonstrate a lack of graph structure awareness which is a key feature of any GNN.
Figures \ref{fig:SGC-BA-Shapes} and \ref{fig:BA-Community} highlight the impure and unstructured concepts typical of SGC.
These results suggest that the linearisation of GCN does not maintain the graph capabilities of GCN contrary to the results and claims of \textit{Wu et al.}.

However, as discussed in \Sref{sec:comp-acc}, the lack of influence that SGC has on node representations is likely the cause.
SGC can only manipulate the final convolution representations which provide limited insight into the structure of the graph.
The extensions described in \Sref{sec:extensions-imp} aim to combat this, providing a fairer comparison between linear and non-linear GNNs.

\section{Extensions}
\label{sec:extension-eval}
\subsection{Evaluation}
All the extensions explored focus on improving or extending SGC.
Therefore these attempts are evaluated using the same techniques used in \Sref{sec:evaluation}.
A subset of the datasets are considered looking at BA Shapes, as the best-performing dataset, and BA Community, as the worst.

\subsection{SGC graph classification}
\label{SGC-graph}

%\begin{figure}
%    \centering
%    \includegraphics[width=0.4\textheight]{figures/SGC-Mutagenicity}
%    \caption{Concepts from SGC and GCN for Mutagenicity comparing the complexity of the inferred graph structure. The numbered concepts are a subset of SGC concepts and the lettered concepts are a subset of GCN. The colour scheme matches standard chemical colours.}
%    \label{fig:SGC-Mutagenicity}
%\end{figure}

\fig{SGC-Mutagenicity}{Concepts from SGC and GCN for Mutagenicity comparing the complexity of the inferred graph structure. The numbered concepts are a subset of SGC concepts and the lettered concepts are a subset of GCN. The colour scheme matches standard chemical colours.}

Tables \ref{tab:SGC-acc}, \ref{tab:SGC-completeness} and \ref{tab:SGC-purity} include the results achieved by SGC on Mutagenicity.
The same quantitative analysis presented in \Sref{sec:quant} can be applied to the results achieved by SGC.
GCN exceeds SGC in accuracy, achieving 93.6\% in comparison to SGC's 61.6\%, and completeness, achieving 0.967 compared to 0.537.
This suggests that synthetic data is not the cause for low performance.
%Comparatively, Mutagenicity is both node representation and graph structure focused due to the nature of molecules.

Figure \ref{fig:SGC-Mutagenicity} further highlights the shortcomings of SGC compared to GCN.
Concepts 1, 2 and 3 focus on the inclusion of a single atom or small molecule structure whereas A, B and C demonstrate complex multi-atom structures.
Concepts 1 and 2 suggest SGC is identifying structure, but, the concepts consistently focus on single atoms, sulphur and nitrogen, whereas Concepts A and B show consistent multi-atom structures.
Concept 3 highlights the focus on grouping by atom as chlorine is the main consistent feature across subgraphs.
In comparison, Concept C highlights how GCN can identify large structures with two cyclic rings identified.

\subsection{SGC and GCN mixed model}
\label{sec:SGCN-eval}

\begin{figure}
    \centering
	\captionsetup{width=.9\textwidth}
    \includegraphics[width=0.40\textheight]{figures/SGCN-latent-space-0}
    \includegraphics[width=0.40\textheight]{figures/SGCN-latent-space-1}
    \includegraphics[width=0.40\textheight]{figures/SGCN-latent-space-2}
    \caption{The 2D t-SNE reduced latent space of the three different models for each GNN layer (ignoring the classifier). Concepts are calculated with the same number of clusters and receptive field. The labels are based on true labels not inferred labels for a better comparison between the models.}
    \label{fig:SGCN-latent-spaces}
\end{figure}

%\fig{SGC-GCN-latent-space}{The 2D t-SNE reduced latent space of the first layer where SGC and GCN activations are most similar based on adjusted mutual information of their concepts. Concepts are calculated with the same number of clusters and receptive field.}
%\fig{SGCN-SGC-latent-space}{The 2D t-SNE reduced latent space of the second layer where SGCN and SGC activations are most similar based on adjusted mutual information of their concepts. Concepts are calculated with the same number of clusters and receptive field.}
%\fig{SGCN-GCN-latent-space}{The 2D t-SNE reduced latent space of the final (third) layer where SGCN and GCN activations are most similar based on adjusted mutual information of their concepts. Concepts are calculated with the same number of clusters and receptive field.}
\input{tables/SGCN-acc}
\input{tables/SGCN-completeness}

As the process of finding, training and evaluating the optimal model requires many steps only BA Shapes is considered.
Figure \ref{fig:SGCN-latent-spaces} shows the t-SNE reduced latent space of each layer and model.
Tables \ref{tab:SGCN-acc} and \ref{tab:SGCN-completeness} demonstrate the results achieved by SGCN in both accuracy and concept completeness.
An analysis of the concepts extracted is presented in \Aref{app:concepts}.

Layer 0 in Figure \ref{fig:SGCN-latent-spaces} presents the first layer which has the highest AMI between GCN and SGC.
The similarity is not very high but is significantly higher than the similarity between SGC and GCN in other layers.
This does present a potential issue in combining models where no significant mutual information is present.

Layer 1 in Figure \ref{fig:SGCN-latent-spaces} demonstrates that the second layer of SGCN is very similar to that of SGC.
This is due to the previous layer being an SGC layer and so the GCN layer is applied to a different feature space.
The spread green labelled nodes (representing the ``floor'') are present in the GCN layer 0 but the arched line is only present in SGC layer 1 demonstrating a mixture of representation.

Layer 2 in Figure \ref{fig:SGCN-latent-spaces} shows that the final layer of SGCN has a latent space that is very similar to that of GCN, almost distinguishing 4 unique groups.
This also demonstrates why SGC performs poorly as it has no clear grouping.

Though SGCN does not surpass the performance of GCN as shown in Table \ref{tab:SGCN-acc} it remains close achieving 95.6\% in comparison to GCN's 98\%.
SGCN achieves a higher completeness score across all layers and highlights a major benefit of the model in maintaining beneficial properties of the GNNs used.

\subsection{Jumping knowledge SGC}
\label{sec:Jump-SGC}

\input{tables/JSGC-acc}
\input{tables/JSGC-completeness}
\input{tables/JSGC-purity}

%\fig{JSGC-latent-space}{The final layer in the GCN, SGC and JSGC architectures for BA Shapes. As shown JSGC has clear clusterings for the different labels similar to GCN but the clustering is not as pronounced likely leading to the lower accuracy. In comparison, SGC exhibits no clear clustering.}

Tables \ref{tab:JSGC-acc}, \ref{tab:JSGC-completeness} and \ref{tab:JSGC-purity} show the results achieved by JSGC.
Overall these demonstrate that JSGC does outperform SGC significantly, by 16.8\% in BA Shapes and 50.1\% in BA Community, and is closer to GCN.
The accuracy achieved by JSGC is still lower than the 95\% suggested by \textit{Ying et al.}~\cite{ying2019gnnexplainer} but significantly better reaching 78.2\%.
This improvement is seen in Table \ref{tab:JSGC-completeness} as the completeness scores match those of GCN, with differences of $-0.021$ and $+0.026$ both within the variation of a decision tree.
The purity for BA Community in Table \ref{tab:JSGC-purity} is higher, 9.4 compared to 4.0 and 5.6, but more concepts were considered.

\begin{figure}
    \centering
	\captionsetup{width=.9\textwidth}
    \includegraphics[width=0.9\textwidth]{figures/JSGC-BA-Community}
    \caption{A subset of concepts from JSGC for BA Community demonstrating the improved graph structure awareness. The concepts are chosen to represent the GCN concepts presented in \ref{fig:BA-Community}. The colour scheme is the same as fig \ref{fig:GCN-BA-Shapes}.}
    \label{fig:JSGC-BA-Community}
\end{figure}

%\fig{JSGC-BA-Community}{A subset of concepts from JSGC for BA Community demonstrating the improved graph structure awareness. The concepts are chosen to represent the GCN concepts presented in \ref{fig:BA-Community}. The colour scheme is the same as fig \ref{fig:GCN-BA-Shapes}.}

Figure \ref{fig:JSGC-BA-Community} highlights the improvements that JSGC has made compared to SGC.
Comparing these concepts to those achieved by GCN presented in Figure \ref{fig:BA-Community} shows a clear improvement.
Concepts 1 to 5 in Figure \ref{fig:JSGC-BA-Community} correspond directly to A to E in Figure \ref{fig:BA-Community}.\footnote{A similar direct mapping was also achieved for BA Shapes.}
JSGC is able to distinguish between the two communities highlighted by Concepts 1 \& 2 and 3 \& 4.
Furthermore, within a community JSGC correctly distinguishes between the different nodes as Concepts 2, 3 and 5 show.
Importantly all concepts, except for the single error in Concept 1, show consistent labelling throughout, particularly in Concept 3 where all nodes are ``outside'' nodes.

\begin{figure}
    \centering
	\captionsetup{width=.9\textwidth}
    \includegraphics[width=0.6\textwidth]{figures/JSGC-latent-space}
    \caption{The final layer in the GCN, SGC and JSGC architectures for BA Shapes. As shown JSGC has clear clusterings for the different labels similar to GCN but the clustering is not as pronounced likely leading to the lower accuracy. In comparison, SGC exhibits no clear clustering.}
    \label{fig:JSGC-latent-space}
\end{figure}

To further highlight the similarity between JSGC and GCN, and the improvement made in comparison to SGC, Figure \ref{fig:JSGC-latent-space} demonstrates the latent space of JSGC.
This demonstrates that JSGC has comparable graph structure awareness to GCN and does not require the non-linearity of GCN to achieve this.
The lower accuracy of JSGC still suggests that there are elements of GCN that are important to its success and generally GRL.
However, further studies into the importance of non-linearity in GRL are required.
