\chapter{Preparation}

\section{Background}

\section{Graph Representational Learning}
\label{sec:GRL}

% Formal definition of graph based data

%% Formal definition of a graph

A \emph{graph} can be formally represented as the tuple $\gG(\sV, \sE, \mX)$ where $\sV$ is the set of nodes in the graph, $\sE$ is the set of edges, and $\mX$ the data associated with the graph also known as the input features.
Two nodes of the graph, $v_i, v_j \in \sV$, are \emph{connected} if and only if $(v_i, v_j) \in \sE$, the edge is directed with $v_i$ as the source and $v_j$ as the destination.
%It is possible to associate data with the edges of the graph where $(v_i, v_j, \textbf{e}_{ij}) \in \sE$ represents a connection between $v_i$ and $v_j$ and associated vector $\textbf{e}_{ij}$.
Each node, $v_i \in \sV$, has associated data represented by the \emph{feature vector} $\vx_i = \emX_{i,\star}$ the $i^{th}$ row of $\mX$.

The edges can be represented as an \emph{adjacency matrix}, $\mA$, where 

\begin{equation*}
\emA_{ij} = \begin{cases}1 &\text{if $(v_i, v_j) \in \sE$} \\ 0 &\text{otherwise}\end{cases}.
\end{equation*}

This allows the edge information to be passed to a NN as another feature vector along with $\mX$.
Furthermore, each node, $v_i \in \sV$, has \emph{neighbours} which is set of connected nodes, $\sN_i = \{v_j | (v_i, v_j) \in \sE \vee (v_j, v_i) \in \sE\}$.
An element of $\sN$ is a therefore a \emph{neighbour} of the node $v_i$.
For ease of writing $\mX_{\sN_i}$ represents the features of the neighbours of $v_i$ defined as $\mX_{\sN_i} = \{\{\vx_j | v_j \in \sN_i\}\}$.\footnote{As the neighbours may have the same feature vector this must be a multiset.}
%If there is data associated with the edges, such as edge weights, this value is stored in the adjacency matrix.
%An unweighted graph can be described as a weighted graph with edge weights of value $1$.
%Adjacency matrices can be very sparse, meaning they have very few non-zero values, and therefore the matrix is commonly stored in a \emph{coordinate matrix} (COO) of size $2 \times N$ for $N$ edges in the graph thus only storing edge information.

% Formal definition of representational learning

The goal of \emph{graph representational learning} (GRL) is to find, for each $v_i \in \sV$, a vector $\vh_i$ based on the the input features $\mX$ and adjacency matrix $\mA$.
$\vh_i$ is known as the \emph{node representation} and $\mH$ is the total graph representation where $\mH_{i, \star} = \vh_i$.

% Comparison of graph, edge and node based learning

%% Expand the above definition to edges and graphs
%% discussion of edge weights in training when talking about edge learning
%% discussion of pooling functions with graph classification

These representations may then be used as input to a classifier to solve one of 3 different classification tasks: node classification, graph classification, link prediction.
For the remainder of this dissertation only node and graph classification will be considered.
Node classification classifies each node solely on the final node representation $\vh_i$.
Comparitively graph classification aggregates all of the node representations and classifies the entire graph accordingly.

\subsection{Graph Neural Networks}

%% Formal definition of a function on this graph
%%      Think about Petars talk here

%% The idea of invariants, equivariants and approaches

To produce updated node representations consider a matrix valued function, $F$, which acts on a graph taking the input features, $\mX$, and adjacency matrix, $\mA$, and producing a new feature matrix $F(\mX, \mA)$.
If this function where to be given instead a different permutation of the graph it is important that the resulting output is permuted the same way.
That is given some permutation, $\mP$, the following must hold

\begin{equation}
    \label{eq:equivar}
    F(\mP\mX, \mP\mA\mP^T) \equiv \mP F(\mX, \mA).\footnote{As the rows and columns of the adjacency matrix must be permuted the permutation matrix is applied twice, with the premultiplication transposed to permute the columns.}
\end{equation}

This principle is known as \emph{equivariance} as the output varies in the same way as the input.

It is also important to consider \emph{invariance} where the result of a function is the same regardless of the permutation. In this case consider the real valued function, $f$, where $f(\mX, \mA)$ is a single real value.

\begin{equation}
    \label{eq:invar}
    f(\mP\mX, \mP\mA\mP^T) \equiv f(\mX, \mA).
\end{equation}

To prevent problems with noise and distortions propagating the function should adhere to locality, that is the representation of a specific node only depends on neighbours.
That is some function

\begin{equation}
    \label{eq:phi}
    \bm{\phi}(\vx_i, \mX_{\sN_i}).
\end{equation}

\ref{eq:phi} gives a definition for $F$ as

\begin{equation}
    F(\mX, \mA) = \begin{bmatrix}\bm{\phi}(\vx_1, \mX_{\sN_1}) \\ \vdots \\ \bm{\phi}(\vx_N, \mX_{\sN_N})\end{bmatrix}.
\end{equation}

\paragraph{Lemma.}
If $\bm{\phi}$ is permutation invariant in $\mX_{\sN_i}$ then $F(\mX, \mA)$ is equivariant.

\paragraph{Proof.}
Let $\pi$ be a permutation of $\sV$, the set of nodes, and $\mP$ the corresponding permutation matrix.
Given $\mX = \begin{bmatrix}\vx_1 \\ \vdots \\ \vx_n\end{bmatrix}$, $\mP\mX = \begin{bmatrix}\vx_{\pi(1)} \\ \vdots \\ \vx_{\pi(N)}\end{bmatrix}$ noting that each node $v_i$ has the same neighbours, $\sN_i$, however the feature matrix of the neighbours is now $\mP\mX_{\sN_i}$. Therefore $F(\mX, \mA) = \begin{bmatrix}\bm{\phi}(\vx_{\pi(1)}, \mP\mX_{\sN_{\pi(1)}}) \\ \vdots \\ \bm{\phi}(\vx_{\pi(N)}, \mP\mX_{\sN_{\pi(N)}})\end{bmatrix}$. As $\bm{\phi}$ is permutation invariant in $\mX_{\sN_i}$, $\bm{\phi}(\vx_{\pi(i)}, \mP\mX_{\sN_{\pi(i)}}) = \bm{\phi}(\vx_{\pi(i)}, \mX_{\sN_{\pi(i)}})$.

Thus 
\begin{align*}
    F(\mP\mX, \mP\mA\mP^T) &= \begin{bmatrix}\bm{\phi}(\vx_{\pi(1)}, \mP\mX_{\sN_{\pi(1)}}) \\ \vdots \\ \bm{\phi}(\vx_{\pi(N)}, \mP\mX_{\sN_{\pi(N)}})\end{bmatrix} \\ 
        &= \begin{bmatrix}\bm{\phi}(\vx_{\pi(1)}, \mX_{\sN_{\pi(1)}}) \\ \vdots \\ \bm{\phi}(\vx_{\pi(N)}, \mX_{\sN_{\pi(N)}})\end{bmatrix} \\
        &= \mP\begin{bmatrix}\bm{\phi}(\vx_1, \mX_{\sN_1}) \\ \vdots \\ \bm{\phi}(\vx_N, \mX_{\sN_N})\end{bmatrix} \\
        &= \mP F(\mX, \mA).
\end{align*}

\error{Fill in the remainder.}

%This function can be described by a function, $f$, which acts on a single node, $v_i$, using the feature vector, $\vx_i$, and neighbours, $\sN_i$.
%Rather than $f$ being applied to the input features consider some node representation $\vh_i^l$ after $l$ iterations, where $\vh_i^0 = \vx_i$.
%Then $\vh_i^{l+1} = f^l(\vh_i^l, \sN_i)$, where $f^l$ is the $l^{th}$ application of the function $f$.

% Formal definition of a graph neural network

%% Expand on the invariants and equivariants above (maybe only start that here)
%% Formalise the notion of how a GNN would behave
%% Discuss the differing approaches

% Potentially the motivation behind this formalisation

%% This is the invariance and equivariance
%% Might be possible to motivate this from the development perspective

% Identify the root of deep learning in its formulation

%% Highlight the concept of non-linear layers
%% potentially a brief discussion on the importance of this concept

\subsection{Graph Convolutional Network}

% Formal implementation of Graph Convolutional Network

%% Expand on the convolutional approach to discuss this formulation

\subsubsection{As a GNN}

The \emph{graph convolutional network} (GCN) is the simplest implementation of the formulation of GNNs outlined above.
The principle is to add the edge weighted sum of a node's neighbour representations to the current node representation.
This maintains the graph function equivariance constraint as sum is equivariant, however, nodes with a high degree are overly represented and so each term is normalised by the degree of the connecting nodes.
This results in the common representation of GCN as

\begin{equation}
    f(\vh_i^l) = \frac1{d_i + 1}\vh_i^l + \sum_j^N\frac{\emA_{ij}}{\sqrt{(d_i + 1)(d_j + 1)}}\vh_j^{l},
\end{equation}

where $d_i$ is the degree of node $v_i$, $d_i = \sum_j^N \emA_{i,j}$.

To better demonstrate that the same operation is being applied to each neighbouring representation (including the nodes current representation) the equation may be rewritten as

\begin{equation}
    f(\vh_i^l) = (d_i + 1)^{-\frac12}1(d_i + 1)^{-\frac12}\vh_i^l + \sum_j^N(d_i + 1)^{-\frac12}\emA_{ij}(d_i + 1)^{-\frac12}\vh_j^{l}.
\end{equation}

Let $\mD$ be the degree matrix, $\emD_{ii} = \sum_j^N \emA_{ij}$, and $\mH^l$ the node representations of the graph after layer $l$. The above equation can now be compactly described as 

\begin{equation}
    F(\mH^l) = (\mD + 1)^{-\frac12}(\mA + \mI)(\mD + 1)^{-\frac12}\mH^l.
\end{equation}

Let $\widetilde{\mA} = \mA + \mI$, then $\widetilde{\mD} = \sum_j^N \widetilde{\mA} = \sum_j^N[\mA] + 1 = \mD + 1$.
Ignoring the application and looking only at the operator which will be called $\mS$, the other representation of a GCN layer is
\begin{equation}
    \mS = \widetilde{\mD}^{-\frac12}\widetilde{\mA}\widetilde{\mD}^{-\frac12}.
\end{equation}

\subsubsection{As a convolution}

The above formulation is often derived from the principle of a convolution applied to the graph.
From this view point $\widetilde{\mA}$ represents a renormalisation of the convolution by adding self-loops where every node in the graph is connected to itself.
The motivation is to prevent exploding/vanishing weights that occur from the approximate graph convolution

\begin{equation}
    \mS = \mI + \mD^{-\frac12}\mA\mD^{-\frac12}
\end{equation}

which has eigenvalues in the range $[0,2]$ rather than remaining at or close to $1$.

\error{How do convolutions and spectral filters arrive at this stage?}

%= \widetilde{\textbf{D}}^{-\frac12}\widetilde{\mA}\widetilde{\textbf{D}}^{-\frac12}\mX\textbf{\Theta}$

% Link to the paper

%% Lay out the exact formulation from the paper
%% Explain this formulation
%% include the motivations/reasonings from the paper

% Discussion of importance in the field?

%% Description of the fact that this is the first graph approach
%% Maybe a link to DeepSet

\subsection{Simplified Graph Convolution}

% Motivation behind SGC

%% Reiterate the points made in the introduction
%% Now specifically highlight these areas in the GCN formulisation

% Demonstration of how the GCN leads to the SGC

%% Demonstrate that the removal of layers logically leads to SGC
%% Explanation of how the weight matrix would behave
%% Potential hint or discussion about the effect of weight decay later

\section{Explainability}

% Overview of the concept of explainability

%% This needs some proper reading in the topic see below

% This probabily requires reading some papers "yay"

\subsection{Concepts}

% Explanation of what a concept is generally

%% Again this requires proper reading in the subject see above

% Relating the explanation to graph based Datasets

%% Demonstrate the idea of concepts translates to subgraphs
%% Focus on the node classification task for this explanation
%% Potentially a motivating example

% Discussion of complications when looking at graph classification

%% Identify the issue when scaling to graph classification
%% Discuss solutions and the chosen solution for this project

\subsection{Graph Concept Explainer}
\label{sec:GCE}

% The motivation for the paper

%% The human in the loop aspect of this project
%% Link in ideas from GNNExplainer

% Discussion of the metrics

%% Formulisation of the two metrics that are presented
%% Discussion what each metric measures with link to results
%% Discussion of short comings of clusterings
%% Discussion of further benefits of latent space

% Detailing why this method was chosen

%% The improvements seen in the paper in regards to visual comparison
%% The clear metrics for comparison

\section{Datasets}

% Continue the concepts in GRL subchapter
% There may be more details about implementation
% May need chapters here or somewhere else about inductive v. transductive!!

To evaluate different GNNs using the metrics described in \Sref{sec:GCE} a trained model needs to be evaluated on specific graphs and concepts extracted from the models inference.
To train the model the a notion of a graph dataset needs to be defined.
As described in \Sref{sec:GRL} there three different classification tasks commonly carried out on graphs (though only two are considered) therefore there are three different notions of a graph dataset.
Node classification datasets assign a class to each node in the dataset, thus each graph has an associated vector, $\vy$, of classifications.
Comparitively, graph classification datasets assign a single value to the entire graph and so each graph is associated with a single value $y$.
A graph dataset is therefore described by its collection of graphs and corresponding labels, $\{(\sG, \vy)\}$ in the case of node classification and $\{(\sG, y)\}$ in the case of graph classification.

However, node classification datasets generally include a single \emph{connected} graph where, in the undirected case, there exists at least one path from every node to every other node.
This creates another distinction between two types of graph datasets:

\paragraph{Transductive datasets} are datasets where during training the node representations of nodes outside of the training set are ``seen'' by the model but importantly the model does not ``see'' the labels for these nodes.
The model will later be tested on the labels of these additional nodes without access to the training sets labels.
This is because the training, validation and test sets are sampled from the nodes, but if only these nodes where given to the model the structure of the graph is lost and a large proportion of the nodes will no longer be connected.
\note{Include a diagram!}.
This dataset forces the model to transfer knowledge about existing representation, label pairs to unlabelled nodes.

\paragraph{Inductive datasets} are datasets where the nodes ``seen'' during training, validation and testing are completely disjoint.
This is generally the case in graph classification tasks where each data point is a unique graph with a classification thus the test set is a new set of graphs with completely unseen nodes.
This dataset forces the model to induce information of relationships between nodes and optimal representations.

As an extension to my project I extended SGC to apply to graph classification tasks thus allowing for analysis of both the transductive and inductive cases of GNNs as well as node and graph classification.

\subsection{Synthetic Datasets}

% From GRL and the overview discuss a bottom up approach
% Discuss how certain properties can be instilled
% Relation to graph theory or importance thereof

To better visualise and analyse concepts for GNNs it is easier to construct graphs with specific properties that produce easy to interpret concepts.
Because these graphs are generated based on desired properties they are considered synthetic graphs.
As discussed in \Sref{sec:GCE} there are five synthetic graphs that were used to analyse concepts for a GCN model.
The construction of these graphs includes a base graph onto which multiple copies of the same \emph{motif} are attached.
The motifs and the base graph have different classifications and the goal is to correctly classify which classification a node belongs to, that is which graph structure is the node part of.

\Sref{sec:GCE} describes the idea of motifs that can be recognised by a GNN and used whilst classifying a node or a graph.

\paragraph{Motifs} are highly ordered graph structures that are easy to identify and differ from the structure of the base graph.
\note{Include diagram of the motifs!}
The five motifs can be seen in the figure \note{reference the figure}.
As these motifs are also very simple they speed up the intensive process of calculating concept purity.

The following two graphs are used as base graphs:

\paragraph{Barabasi-Albert}
a densely connected graph where nodes are probabilisitically connected to each other.
The probability of a node connecting to another depends on the existing degree of the node thus keeping limiting the maximum degree of a node in the graph.

\paragraph{Tree}
a binary symmetric tree of height 8 and is therefore very sparse in comparison to Barabasi.
These two base graphs provide two different scenarios to compare a models ability to identify the motifs accurately.

Not all motifs and base graphs are paired together and only BA-Shapes\footnote{Which utilises the house motif}, BA-Grid, Tree-Grid and Tree-Cycles are considered.
There is an additional synthetic dataset, BA-Community, which combines two BA-Shapes graphs and requires the model distinguish between the communities as well as identify the motifs.

Node features for all the graphs are all-$1$ vectors of length 10, except in the case of BA-Community where one of the communities has all-$2$ vectors of length 10.

\subsection{Real-World Datasets}

% Linking to motivation and GRL
% Demonstrating that these techniques are important for real world use
% Discussions of the short comings of this approach

As an extension and to produce meaningful results that reflect real-world applications of GNNs two real world datasets are also tested against.
These two datasets are graph classification datasets and therefore inductive datasets compared to the transductive synthetic datasets.
These datasets are part of TUDataset \cite{Morris+2020} available through \texttt{PyTorch Geometric}.

\paragraph{REDDIT BINARY}
is a dataset where each graph represents a discussion on Reddit with nodes being users and an edge represents one user responding to anothers comment.
The discussions are sampled from IAmA, AskReddit, TrollXChromosomes, and atheism.
IAmA and AskReddit are question-answer based whereas TrollXChromosomes and atheism are discussion based.
The task is to classify the graphs as question-answer or discussion based.

\paragraph{Mutagenicity}
is a dataset where each graph is a chemical compound where nodes are atoms and edges are chemical bonds.
The chemical compounds correspond to drugs some of which are mutagens and the rest are not.
The task is to classify the graphs as to whether or not they are mutagens.

\section{Tools Used}

% I believe this is stuff like vim
% Pytorch, pytorch lightning and pytorch geometric
% scipy and numpy
% python unittest and typing
% python linter through vim

\paragraph{Programming languages}
I use Python to write the majority of the software as there is a lot of existing support for machine learning frameworks.
Furthermore, Python is easy to read, debug and iterate in which is very useful for developing and testing new methods.

To reduce the need for human input when running multiple experiments to get confidence intervals or hyperparameter tuning I also use bash scripts.
And to allow for easier reproducibility and iteration I utilise YAML files to store build configurations for all of my models.

\paragraph{Software development}

I use \texttt{NeoVim} to develop my code as this has high customisability allowing me to include specific linters to highlight bugs, typing errors and general static code analysis.
Additionally I use a local \texttt{Tensorboard} instance to visualise and analyse progress of my experiments in realtime, \texttt{Git} and \texttt{Github} \note{Citation needed?}for version control with \texttt{scp} and the \texttt{Student Run Computing Facility} as a third backup of experiment results.
I occasionally used \texttt{Google Colab} for compute units to run the large experiment batches.

\paragraph{Libraries}
\label{sec:libraries}

The major libraries I used where the two ML libraries \texttt{PyTorch} \note{Citation needed} and \texttt{PyTorch Geometric} \cite{Fey/Lenssen/2019} an extension to \texttt{PyTorch} which includes support for GRL.
\texttt{PyTorch} was chosen over Tensorflow as it is more ``pythonic'' and \texttt{PyTorch Geometric} is a simpler framework to use.
To help with running experiments, logging results and reproducibility I use \texttt{Lightning AI} which handles the underlying training and testing loop while integrating with Tensorboard.
\texttt{Hyperopt} is also used as \textit{Wu et al.}\cite{wu2019simplifying} state this method was used to find the weight decay hyperparameter.

For scientific computing when analysing concepts I use \texttt{Numpy} and \texttt{scikit-learn}. For the visualisation of graphs I use \texttt{NetworkX} to draw the graphs and \texttt{Matplotlib} to visualise and store the result, I also use \texttt{Matplotlib} to visualise hyperparameter surfaces. Note that \texttt{NetworkX} is included in the \texttt{PyTorch Geometric} library automatically.

For unit tests I use Python's own \texttt{unittest} library, to help with software development I use Python's \texttt{typing} library alongside the built in typing functionality of my other libraries. Additionally I occasionally use \texttt{tqdm} to visualise progress during concept analysis.

\section{Requirements Analysis}

% definitely think this is useful
% to be figured out later

\section{Software Methodology}

% Generally waterfall approach to design
% But iterative when looking at the results and direction forward
% sprint work style between meetings

For the core of my project I adopt a Waterfall method \note{Citation needed} for my project:

\begin{equation*}
    \textit{Requirements analysis} \longrightarrow \textit{Design} \longrightarrow \textit{Implementation} \longrightarrow \textit{Testing} \longrightarrow \textit{Evaluation}
\end{equation*}

During the \textit{Design} phase I start with a skeleton implementation of the ML pipeline and focus on each of the requirements in turn carrying out both \texttt{Implementation} and \texttt{Testing} together where possible.
At each stage I confirm that the implemented requirement integrates with the rest of the project using a combination of predetermined dummy data, dummy models and dummy concept analysis where these aspects where not yet implemented.
\textit{Evaluation} stage includes all the experiment runs and concept analysis required to meet my success criteria replacing \textit{Operations} which is not required for my project.

My extensions do not fit into the Waterfall method as they are research based in nature. I therefore switch to an Agile software development \note{Citation needed} to allow the project to adjust to the experimental results achieved during development.

\section{Testing}

% unittest for specific sections of code and infrastructure
% comparison to paper baselines when dealing with model implementation

Machine learning does not provide precise metric against which correctness of an implementation can be verified.
This is due to the multiple factors that contribute to a machine learning models performance such as hyperparameters, initialisation/random seeds, architecture and dataset.
As example a trained model may result in poor results because the underlying architecture is not suited to the dataset, there is too much noise in the data to properly train, or because there is a software bug.
Thus, unlike traditional software development, it is much harder to verify that an ML model or algorithm has been implemented correctly.
However, my project does include software that follows traditional software development and therefore a use the following two testing approaches:

\paragraph{Unit testing}
is suitable for traditional software development where a specific result is required for specific input.
The concept analysis and dataset handling fall into this category.
These two aspects are therefore verified using unit testing described later. \note{Remember to include reference when complete.}

\paragraph{Reproduction of prior results}
The two main models I use, GCN and SGC, directly follow implementations of the work by \textit{Kipf et al.}\cite{kipf2016semi} and \textit{Wu et al.}\cite{wu2019simplifying}. The hyperparameters for the GCN model baseline are available in \textit{Magister et al.}\cite{magister2021gcexplainer} where accuracy scores are also published. In \note{Reference the section when complete} I reproduce the experiment results to verify my ML pipeline, NN implementations and dataset integration.

\section{Licensing}

\begin{wraptable}{r}{8.5cm}
    \begin{tabular}{cc}
        \multicolumn{1}{c}{\textbf{Software dependency}} &
        \multicolumn{1}{c}{\textbf{License}} \\ 
        \midrule
        NumPy & \multirow{5}{*}{3-clause BSD} \\
        scikit-learn & \\
        NetworkX & \\
        PyTorch & \\
        hyperopt \tablefootnote{The license is unnamed by matches the 3-clause BSD license verbatim.} & \\
        \rowcolor{gray!20} tensorboard & \\
        \rowcolor{gray!20} Lightning AI &  \multirow{-2}{*}{Apache 2.0}\\
        matplotlib & \\
        Python & \multirow{-2}{*}{PSFL}\\
        \rowcolor{gray!20}
        PyTorch Geometric & \\
        \rowcolor{gray!20}
        tqdm & \multirow{-2}{*}{MIT} \\
        tqdm & MPL\tablefootnote{tqdm is distributed under both licenses.} \\
    \end{tabular}
    \caption{Licenses for the project dependencies}
    \label{tab:licensing}
\end{wraptable}
%\include{tables/licensing}
All software dependencies used in my project are under permissive licenses allowing me to use the code with no restrictions.
Furthermore, I am free to use the Planetoid \note{Cite Zhilin Yang, Revisiting} and TUDataset \cite{Morris+2020} datasets available in \texttt{PyTorch Geometric} library.
Though some licenses have additional restrictions on source code modification and/or redistribution my project does neither of these actions and only uses the libraries as is.

I license my source code under the MIT license to support further developers and researchers.
This licensing complies with the licenses of my dependencies.

% Definitely need to research this aspect

\section{Starting Point}

My starting point is the same as the starting point declared in my proposal except for the additional information that the research paper over the summer has resulted in an acceptance to Learning on Graphs 2022.
I use the \texttt{PyTorch Geometric} implementation of GCN layers to build the GCN network, as this is just a baseline model. I also rely on the libraries discussed in \Sref{sec:libraries}.
Aside from these dependencies I built the project from scratch.

% Discussion of summer project using the same rough build environment
